---
title: "Повторение сопряженных множеств и сопряженных функций. Субградиент и субдифференциал"
author: Даниил Меркулов
institute: Методы оптимизации. МФТИ
format: 
    beamer:
        pdf-engine: xelatex
        aspectratio: 169
        fontsize: 9pt
        section-titles: true
        incremental: true
        include-in-header: ../files/xeheader.tex  # Custom LaTeX commands and preamble
header-includes:
 - \newcommand{\bgimage}{../files/back13.jpeg}
---

# Сопряженные множества

## Сопряженное множество

:::: {.columns}
::: {.column width="50%"}
Пусть $S \subseteq \mathbb{R}^n$ — произвольное непустое множество. Тогда его сопряжённое множество определяется как:
$$
S^* = \{y \in \mathbb{R}^n \mid \langle y, x\rangle \ge -1 \;\; \forall x \in S\}
$$
\pause

Множество $S^{**}$ называется двойным сопряжённым множеством к $S$, если:
$$
S^{**} = \{y \in \mathbb{R}^n \mid \langle y, x\rangle \ge -1 \;\; \forall x \in S^*\}
$$
\pause

* Множества $S_1$ и $S_2$ называются **взаимно сопряжёнными**, если $S_1^* = S_2,\; S_2^* = S_1$.
* Множество $S$ называется **самосопряжённым**, если $S^{*} = S$.
:::

::: {.column width="50%"}
![Выпуклые множества можно описывать двойственным образом — через элементы множества и через множество опорных гиперплоскостей](conjugate_set.pdf){#fig-conjugate_set}
:::
::::

## Свойства сопряжённых множеств

* Сопряжённое множество всегда замкнуто, выпукло и содержит нуль.
* Для произвольного множества $S \subseteq \mathbb{R}^n$:  

    $$
     S^{**} = \overline{ \mathbf{conv} (S \cup \{0\}) }
    $$

* Если $S_1 \subseteq S_2$, то $S_2^* \subseteq S_1^*$.
* $\left( \bigcup\limits_{i=1}^m S_i \right)^* = \bigcap\limits_{i=1}^m S_i^*$.
* Если $S$ замкнуто, выпукло и содержит $0$, то $S^{**} = S$.
* $S^* = \left(\overline{S}\right)^*$.


## Пример 1 {.t}

::: {.callout-example}
Доказать, что $S^* = \left(\overline{S}\right)^*$.
:::

. . .

* $S \subset \overline{S} \;\;\Rightarrow\;\; \left(\overline{S}\right)^* \subset S^*$.
* Пусть $p \in S^*$ и $x_0 \in \overline{S}, \; x_0 = \underset{k \to \infty}{\operatorname{lim}} x_k$.  Тогда в силу непрерывности функции $f(x) = p^T x$ имеем: $p^T x_k \ge -1 \;\;\Rightarrow\;\; p^T x_0 \ge -1$. Следовательно, $p \in \left(\overline{S}\right)^*$, и значит $S^* \subset \left(\overline{S}\right)^*$.


## Пример 2 {.t}

::: {.callout-example}
Доказать, что $\left( \mathbf{conv}(S) \right)^* = S^*$.
:::

. . .

* $S \subset \mathbf{conv}(S) \;\;\Rightarrow\;\; \left( \mathbf{conv}(S) \right)^* \subset S^*$.
* Пусть $p \in S^*$ и $x_0 \in \mathbf{conv}(S)$, то есть  
  $$ x_0 = \sum\limits_{i=1}^k \theta_i x_i,\;\; x_i \in S,\;\; \sum\limits_{i=1}^k \theta_i = 1,\;\; \theta_i \ge 0$$.
* Тогда
  $$
  p^T x_0 = \sum\limits_{i=1}^k \theta_i \, p^T x_i \;\ge\; \sum\limits_{i=1}^k \theta_i \cdot (-1) = 1 \cdot (-1) = -1.
  $$
* Значит, $p \in \left( \mathbf{conv}(S) \right)^*$, и, следовательно, $S^* \subset \left( \mathbf{conv}(S) \right)^*$.


## Пример 3 {.t}

::: {.callout-example}
Докажите, что если $B(0,r)$ — это шар радиуса $r$ в некоторой норме с центром в нуле, то $\left( B(0,r) \right)^* = B(0,1/r)$.
:::

. . .

:::: {.columns}
::: {.column width="50%"}

* Пусть $B(0,r) = X,\; B(0,1/r) = Y$. Возьмём вектор $p \in X^*$, тогда для любого $x \in X$: $p^Tx \ge -1$.
* Среди всех точек шара $X$ возьмём такую $x \in X$, для которой скалярное произведение с $p$ минимально: $p^Tx$. Это точка $x = -\dfrac{p}{\|p\|} r$.

    $$
    p^T x = p^T \left(-\dfrac{p}{\|p\|} r \right) = -\|p\| r \ge -1
    $$

    $$
    \|p\| \le \dfrac{1}{r} \in Y
    $$

    Следовательно, $X^* \subset Y$.

:::

::: {.column width="50%"}
* Теперь пусть $p \in Y$. Нужно показать, что $p \in X^*$, то есть $\langle p, x\rangle \ge -1$. Достаточно применить неравенство Коши–Буняковского:

    $$
    \|\langle p, x\rangle\| \le \|p\| \|x\| \le \dfrac{1}{r} \cdot r = 1
    $$

    Последнее верно, так как $p \in B(0,1/r)$ и $x \in B(0,r)$.
  
    Следовательно, $Y \subset X^*$.
:::
::::


## Двойственный конус

Сопряжённым (двойственным) к конусу $K$ называется множество $K^*$ такое, что: 
$$
K^* = \left\{ y \mid \langle x, y\rangle \ge 0 \quad \forall x \in K \right\}
$$
\pause
Чтобы показать, что это определение напрямую вытекает из предыдущих определений, напомним, что такое сопряжённое множество и что такое конус при $\forall \lambda > 0$.

$$
\{y \in \mathbb{R}^n \mid \langle y, x\rangle \ge -1 \;\; \forall x \in S\}
   \;\;\to\;\;
\{\lambda y \in \mathbb{R}^n \mid \langle y, x\rangle \ge -\dfrac{1}{\lambda} \;\; \forall x \in S\}
$$

![](dual_cones.pdf){#fig-conjugate_cone width=73%}


## Свойства двойственных конусов

* Пусть $K$ — замкнутый выпуклый конус. Тогда $K^{**} = K$.
* Для произвольного множества $S \subseteq \mathbb{R}^n$ и конуса $K \subseteq \mathbb{R}^n$:  

    $$
    \left( S + K \right)^* = S^* \cap K^*
    $$

* Пусть $K_1, \ldots, K_m$ — конусы в $\mathbb{R}^n$, тогда:  

    $$
    \left( \sum\limits_{i=1}^m K_i \right)^* = \bigcap\limits_{i=1}^m K_i^*
    $$

* Пусть $K_1, \ldots, K_m$ — конусы в $\mathbb{R}^n$. Если их пересечение имеет внутреннюю точку, то:  

    $$
    \left( \bigcap\limits_{i=1}^m K_i \right)^* = \sum\limits_{i=1}^m K_i^*
    $$


## Пример {.t}

::: {.callout-example}
Найдите сопряжённый конус для монотонного неотрицательного конуса:  
$$
K = \left\{ x \in \mathbb{R}^n \mid x_1 \ge x_2 \ge \ldots \ge x_n \ge 0 \right\}
$$
:::
\pause
Заметим, что:  
$$
\sum\limits_{i=1}^n x_i y_i = y_1 (x_1 - x_2) + (y_1 + y_2)(x_2 - x_3) + \ldots + (y_1 + y_2 + \ldots + y_{n-1})(x_{n-1} - x_n) + (y_1 + \ldots + y_n) x_n
$$
\pause
Так как во всей представленной сумме второй множитель в каждом слагаемом неотрицателен, то:  
$$
y_1 \ge 0,\;\; y_1 + y_2 \ge 0,\;\;\ldots,\;\; y_1 + \ldots + y_n \ge 0
$$

Следовательно, $K^* = \left\{ y \mid \sum\limits_{i=1}^k y_i \ge 0,\;\; k = \overline{1,n} \right\}.$

## Многогранники

:::: {.columns}
::: {.column width="60%"}
Множество решений системы линейных неравенств и равенств является многогранником:  
$$
Ax \preceq b, \;\;\; Cx = d
$$
Здесь $A \in \mathbb{R}^{m\times n},\; C \in \mathbb{R}^{p \times n}$, а знак неравенства понимается покомпонентно.
\pause

::: {.callout-theorem}
Пусть $x_1, \ldots, x_m \in \mathbb{R}^n$. Тогда сопряжённым к многогранному множеству  

$$
S = \mathbf{conv}(x_1, \ldots, x_k) + \mathbf{cone}(x_{k+1}, \ldots, x_m) 
$$

является многогранник:  

$$
S^* = \left\{ p \in \mathbb{R}^n \;\middle|\; \langle p, x_i\rangle \ge -1,\; i = \overline{1,k};\;\; \langle p, x_i\rangle \ge 0,\; i = \overline{k+1,m} \right\}
$$
:::


:::

::: {.column width="40%"}
![Polyhedra](polyhedra.pdf){#fig-polyhedra}
:::
::::


## Доказательство

* Пусть $S = X,\; S^* = Y$. Возьмём некоторое $p \in X^*$, тогда $\langle p, x_i\rangle \ge -1,\; i = \overline{1,k}$. В то же время, для любого $\theta > 0,\; i = \overline{k+1,m}$: 
  
    $$
    \langle p, x_i\rangle \ge -1 \to \langle p, \theta x_i\rangle \ge -1
    $$

    $$
    \langle p, x_i\rangle \ge -\frac{1}{\theta} \to \langle p, x_i\rangle \geq 0. 
    $$

    Следовательно, $p \in Y \to X^* \subset Y$.

* Предположим, наоборот, что $p \in Y$. Для любой точки $x \in X$: $x = \sum\limits_{i=1}^m\theta_i x_i , \ \ \sum\limits_{i=1}^k\theta_i = 1,\;\; \theta_i \ge 0$  
    Тогда:  

    $$
    \langle p, x\rangle = \sum\limits_{i=1}^m\theta_i \langle p, x_i\rangle = \sum\limits_{i=1}^k\theta_i \langle p, x_i\rangle + \sum\limits_{i=k+1}^m\theta_i \langle p, x_i\rangle \ge \sum\limits_{i=1}^k\theta_i (-1) + \sum\limits_{i=1}^k\theta_i \cdot 0 = -1.
    $$

    Следовательно, $p \in X^* \to Y \subset X^*$.


## Пример

# Сопряжённые функции

## Сопряжённые функции

:::: {.columns}
::: {.column width="60%"}
![](conj_function.pdf)
:::
::: {.column width="40%"}
Напомним, что для отображения $f : \mathbb{R}^n \rightarrow \mathbb{R}$ функция, определяемая как  
$$
f^*(y) = \max_x \left[ y^T x - f(x) \right]
$$ 
называется его сопряжённой. Выражение выше называется преобразованием Лежандра.
:::
::::

## Геометрическая интуиция

:::: {.columns}
::: {.column width="60%"}
![](conj_question.pdf)
:::

. . .

::: {.column width="41%"}
![](conj_answer.pdf)
:::
::::

## Наклон $f$ и $f^*$

![Геометрический смысл $f^*$](conj_slope.pdf)

## Наклон $f$ и $f^*$

Предположим, что $f$ — замкнутая и выпуклая функция. Тогда $f$ сильно выпукла с параметром $\mu$ $\Leftrightarrow$ $\nabla f^*$ является липшицевой с параметром $1/\mu$.

. . .

**Доказательство “$\Rightarrow$”**: напомним, если $g$ сильно выпукла с минимайзером $x$, то  
$$
g(y) \geq g(x) + \frac{\mu}{2} \|y - x\|^2, \quad \text{для всех } y
$$

. . .

Введём обозначения $x_u = \nabla f^*(u)$ и $x_v = \nabla f^*(v)$, тогда  
$$
\begin{aligned}
f(x_v) - u^T x_v &\geq f(x_u) - u^T x_u + \frac{\mu}{2} \|x_u - x_v\|^2 \\
f(x_u) - v^T x_u &\geq f(x_v) - v^T x_v + \frac{\mu}{2} \|x_u - x_v\|^2
\end{aligned}
$$

. . .

Сложив эти неравенства, применяя неравенство Коши–Буняковского-Шварца и преобразуя, получаем:  
$$
\|x_u - x_v\|^2 \leq \frac{1}{\mu} \|u - v\|^2
$$


## Наклон $f$ и $f^*$

**Доказательство “$\Leftarrow$”**: для простоты обозначим $g = f^*$ и $L = \tfrac{1}{\mu}$. Так как $\nabla g$ является липшицевой с константой $L$, то и $g_x(z) = g(z) - \nabla g(x)^T z$ также липшицева, следовательно  
$$
g_x(z) \leq g_x(y) + \nabla g_x(y)^T (z - y) + \frac{L}{2} \|z - y\|^2_2
$$

. . .

Минимизируя обе части по $z$ и преобразуя, получаем  
$$
\frac{1}{2L} \|\nabla g(x) - \nabla g(y)\|^2 \leq g(y) - g(x) + \nabla g(x)^T (x - y)
$$

. . .

Меняя местами $x$, $y$ и складывая, получаем  
$$
\frac{1}{L}\|\nabla g(x) - \nabla g(y)\|^2 \leq (\nabla g(x) - \nabla g(y))^T (x - y)
$$

. . .

Положим $u = \nabla f(x)$, $v = \nabla g(y)$; тогда $x \in \partial g^*(u)$, $y \in \partial g^*(v)$, и выше получаем  
$$
(x - y)^T (u - v) \geq \frac{\|u - v\|^2}{L},
$$  
что и доказывает утверждение.


## Свойства сопряжённых функций

Напомним, что для отображения $f : \mathbb{R}^n \rightarrow \mathbb{R}$ функция, определяемая как  
$$
f^*(y) = \max_x \left[ y^T x - f(x) \right]
$$ 
называется его сопряжённой.

* Сопряжённые функции часто возникают в двойственных задачах, так как  
    $$
    -f^*(y) = \min_x \left[ f(x) - y^T x \right]
    $$
* Если $f$ замкнута и выпукла, то $f^{**} = f$. Кроме того,  
    $$
    x \in \partial f^*(y) \Leftrightarrow y \in \partial f(x) \Leftrightarrow x \in \arg \min_z \left[ f(z) - y^T z \right]
    $$
* Если $f$ строго выпукла, то  
    $$
    \nabla f^*(y) = \arg \min_z \left[ f(z) - y^T z \right]
    $$


## Свойства сопряжённой функции (доказательства)

Покажем, что $x \in \partial f^*(y) \Leftrightarrow y \in \partial f(x)$, предполагая, что $f$ выпукла и замкнута.

* **Доказательство $\Leftarrow$**: Пусть $y \in \partial f(x)$. Тогда $x \in M_y$ — множество точек максимума $y^T z - f(z)$ по $z$. Но 
    $$
    f^*(y) = \max_z \{y^T z - f(z)\}\quad\text{ and }\quad\partial f^*(y) = \text{cl}(\text{conv}(\bigcup_{z \in M_y} \{z\})).
    $$
    Следовательно, $x \in \partial f^*(y)$.

* **Доказательство $\Rightarrow$**: Из показанного выше, если $x \in \partial f^*(y)$, то $y \in \partial f^*(x)$, но $f^{**} = f$.

. . .

Очевидно, $y \in \partial f(x) \Leftrightarrow x \in \arg \min_z \{f(z) - y^T z\}$

Наконец, если $f$ строго выпукла, то мы знаем, что $f(z) - y^T z$ имеет единственный минимизатор по $z$, и им должна быть $\nabla f^*(y)$.

## Прямое следствие нерваенства Фенхеля-Юнга $f(x) \ge f^{\star\star}(x)$.

![](double_conjugate.pdf)



# Негладкие задачи

## Задача наименьших квадратов с $\ell_1$- регуляризацией

[![](l1_regularization.jpeg)](https://fmin.xyz/assets/Notebooks/Regularization_horizontal.mp4)

## Нормы не являются гладкими

$$
\min_{x \in \mathbb{R}^n} f(x),
$$

Рассмотрим классическую выпуклую задачу оптимизации. Мы предполагаем, что $f(x)$ является выпуклой функцией, но теперь мы не требуем гладкости. 

![Нормы конусов для разных $p$ — нормы не являются гладкими](norm_cones.pdf){width=90%}

## Пример Вульфа

![Пример Вульфа. [\faPython Открыть в Colab](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/subgrad.ipynb)](wolfe_3d.pdf){width=90%}


# Вычисление субградиента

## Линейная нижняя оценка выпуклых функций

:::: {.columns}

::: {.column width="60%"}
![Линейная аппроксимация Тейлора служит глобальной нижней оценкой для выпуклой функции](Subgrad.pdf)
:::

::: {.column width="40%"}
Важное свойство непрерывной выпуклой функции $f(x)$ заключается в том, что для любой выбранной точки $x_0$ для всех $x \in \text{dom } f$ выполняется неравенство:
$$
f(x) \geq f(x_0) + \langle g, x - x_0 \rangle
$$

. . .

для некоторого вектора $g$, т.е. касательная к графику функции является *глобальной* нижней оценкой для функции. 

* Если $f(x)$ дифференцируема, то $g = \nabla f(x_0)$.
* Не все непрерывные выпуклые функции дифференцируемы.

. . .

Мы не хотим потерять такое удобное свойство.
:::

::::

## Субградиент и субдифференциал

Вектор $g$ называется **субградиентом** функции $f(x): S \to \mathbb{R}$ в точке $x_0$, если $\forall x \in S$:
$$
f(x) \geq f(x_0) + \langle g, x - x_0 \rangle
$$

. . .

Множество всех субградиентов функции $f(x)$ в точке $x_0$ называется **субдифференциалом** функции $f$ в точке $x_0$ и обозначается $\partial f(x_0)$.

. . .

![Субдифференциал — это множество всех возможных субградиентов](Subdifferential.pdf)

## Субградиент и субдифференциал

Найдите $\partial f(x)$, если $f(x) = |x|$

. . .

![Субдифференциал $\vert x \vert$](subgradmod.pdf){width=85%}

## Свойства субдифференциала

:::: {.columns}
::: {.column width="50%"}
* Если $x_0 \in \mathbf{ri }(S)$, то $\partial f(x_0)$ является выпуклым компактным множеством.
* Выпуклая функция $f(x)$ дифференцируема в точке $x_0\Rightarrow \partial f(x_0) = \{\nabla f(x_0)\}$.
* Если $\partial f(x_0) \neq \emptyset \quad \forall x_0 \in S$, то $f(x)$ выпукла на $S$.

. . .


::: {.callout-theorem}

### Субдифференциал дифференцируемой функции

Пусть $f : S \to \mathbb{R}$ — функция, определенная на множестве $S$ в евклидовом пространстве $\mathbb{R}^n$. Если $x_0 \in \mathbf{ri }(S)$ и $f$ дифференцируема в точке $x_0$, то либо $\partial f(x_0) = \emptyset$ либо $\partial f(x_0) = \{\nabla f(x_0)\}$. Более того, если функция $f$ выпукла, то первая ситуация невозможна.
:::
:::

. . .

::: {.column width="50%"}

**Доказательство**

1. Пусть $s \in \partial f(x_0)$ для некоторого $s \in \mathbb{R}^n$ отличного от $\nabla f(x_0)$. Пусть $v \in  \mathbb{R}^n$ — единичный вектор. Поскольку $x_0$ является внутренней точкой множества $S$, существует $\delta > 0$ такое, что $x_0 + tv \in S$ для всех $0 < t < \delta$. По определению субградиента:
 $$
    f(x_0 + tv) \geq f(x_0) + t \langle s, v \rangle
 $$

. . .

что влечёт:
$$
\frac{f(x_0 + tv) - f(x_0)}{t} \geq \langle s, v \rangle
$$
для всех $0 < t < \delta$. Переходя к пределу при $t \to 0$ и используя определение градиента, получаем:
$$
\langle \nabla f(x_0), v \rangle = \lim_{{t \to 0; 0 < t < \delta}} \frac{f(x_0 + tv) - f(x_0)}{t} \geq \langle s, v \rangle
$$
:::
::::

## Свойства субдифференциала

2. Отсюда $\langle s - \nabla f(x_0), v \rangle \geq 0$. В силу произвольности $v$ можно выбрать 
 $$
    v = -\frac{s - \nabla f(x_0)}{\| s - \nabla f(x_0) \|},
    $$ 
 которое приводит к $s = \nabla f(x_0)$.
3. Более того, если функция $f$ выпукла, то согласно дифференциальному условию выпуклости $f(x) \geq f(x_0) + \langle \nabla f(x_0), x - x_0 \rangle$ для всех $x \in S$. Но по определению это означает, что $\nabla f(x_0) \in \partial f(x_0)$.


## Вычисление субдифференциалов

:::: {.columns}
::: {.column width="50%"}
:::{.callout-theorem}
### Теорема Моро — Роккафеллара (субдифференциал линейной комбинации)
Пусть $f_i(x)$ — выпуклые функции на выпуклых множествах $S_i, \; i = \overline{1,n}$. Тогда если $\bigcap\limits_{i=1}^n \mathbf{ri } (S_i) \neq \emptyset$, то функция $f(x) = \sum\limits_{i=1}^n a_i f_i(x), \; a_i > 0$ имеет субдифференциал $\partial_S f(x)$ на множестве $S = \bigcap\limits_{i=1}^n S_i$ и 
$$
\partial_S f(x) = \sum\limits_{i=1}^n a_i \partial_{S_i} f_i(x).
$$
:::
:::

. . .

::: {.column width="50%"}
::: {.callout-theorem}

### Теорема Дубовицкого — Милютина (субдифференциал поточечного максимума) 

Пусть $f_i(x)$ — выпуклые функции на открытом выпуклом множестве $S \subseteq \mathbb{R}^n, \; x_0 \in S$, и поточечный максимум определяется как $f(x) = \underset{i}{\operatorname{max}} f_i(x)$. Тогда:
$$
\partial_S f(x_0) = \mathbf{conv}\left\{  \bigcup\limits_{i \in I(x_0)} \partial_S f_i(x_0) \right\},
$$
$$
\quad I(x) = \{ i \in [1:m]: f_i(x) = f(x)\}
$$
:::
:::
::::

## Вычисление субдифференциала

* $\partial (\alpha f)(x) = \alpha \partial f(x)$, для $\alpha \geq 0$
* $\partial (\sum f_i)(x) = \sum \partial f_i (x)$, $f_i$ — выпуклые функции
* $\partial (f(Ax + b))(x) = A^T\partial f(Ax + b)$, $f$ — выпуклая функция
* $z \in \partial f(x)$ тогда и только тогда, когда $x \in \partial f^*(z)$.

## Связь с выпуклой геометрией

:::: {.columns}
::: {.column width="60%"}

Для выпуклого множества $S \subseteq \mathbb{R}^n$, рассмотрим индикаторную функцию $I_S : \mathbb{R}^n \to \mathbb{R}$,

$$
I_S(x) = I\{ x \in S \} = \begin{cases} 
0 & \text{if } x \in S \\
\infty & \text{if } x \notin S 
\end{cases}
$$

Для $x \in S$, $\partial I_S(x) = \mathcal{N}_S(x)$, **нормальный конус** для $S$ в $x$:

$$
\mathcal{N}_S(x) = \{ g \in \mathbb{R}^n : g^T x \geq g^T y \text{ for any } y \in S \}
$$

**Почему?** По определнию субградиента $g$,

$$
I_S(y) \geq I_S(x) + g^T (y - x) \quad \text{for all } y
$$

- При $y \notin S$, $I_S(y) = \infty$
- При $y \in S$, this means $0 \geq g^T (y - x)$

:::

::: {.column width="40%"}
![](normal_cone.jpg)
:::
::::

## Условия Оптимальности

Для любой $f$ (выпуклой или нет),
$$
f(x^\star) = \min_x f(x) \quad \Longleftrightarrow \quad 0 \in \partial f(x^\star)
$$

То есть, $x^\star$ является точкой минимума тогда и только тогда, когда 0 является субградиентом функции $f$ в точке $x^\star$. Это утверждение называется **субградиентное условие оптимальности**

Почему? Легко: если $g = 0$ является субградиентом, это значит что для всех $y$ 
$$
f(y) \geq f(x^\star) + 0^T (y - x^\star) = f(x^\star)
$$

Отметим, что для выпуклой и дифференцируемой функций $f$ верно
$$
\partial f(x) = \{\nabla f(x)\}
$$

## Получение условия оптимальности первого порядка

:::: {.columns}
::: {.column width="50%"}

Пример мощи субградиентов: мы можем использовать всё, что узнали ранее, для получения **условия оптимальности первого порядка**. Вспомним, решением задачи

$$
\min_x f(x) \text{ subject to } x \in S
$$

является точка $x$, для выпуклой и дифференцируемой $f$, в том и только в том случае, если

$$
\nabla f(x)^T (y - x) \geq 0 \quad \text{for all } y \in S
$$

Интуитивно: написанное выше означает, что градиент увеличивается по мере движения от точки $x$. Как это доказать? Во-первых, перепишем задачу в следующем виде:

$$
\min_x f(x) + I_S(x)
$$

Теперь воспользуемся условием оптимальности в субградиентной форме:

$$
0 \in \partial (f(x) + I_S(x))
$$

:::
::: {.column width="50%"}
![](general_first_order_local_optimality.pdf)
:::
::::


## Получение условия оптимальности первого порядка {.noframenumbering}

:::: {.columns}
::: {.column width="50%"}

Observe

$$0 \in \partial (f(x) + I_S(x))$$

$$\Leftrightarrow 0 \in \{\nabla f(x)\} + \mathcal{N}_S(x)$$

$$\Leftrightarrow -\nabla f(x) \in \mathcal{N}_S(x)$$

$$\Leftrightarrow -\nabla f(x)^T x \geq -\nabla f(x)^T y \text{ for all } y \in S$$

$$\Leftrightarrow \nabla f(x)^T (y - x) \geq 0 \text{ for all } y \in S$$

что и требовалось.

Замечание: условие $0 \in \partial f(x) + \mathcal{N}_S(x)$ является **общим условием** оптимальности для выпуклых задач. Однако с ним не всегда удобно работать (ККТ удобнее, про них позже). 

:::
::: {.column width="50%"}
![](general_first_order_local_optimality.pdf)
:::
::::

## Пример 1

::: {.callout-example}
Найти $\partial f(x)$, if $f(x) = |x - 1| + |x + 1|$
:::

. . .

$$
\partial f_1(x) = \begin{cases} -1,  &x < 1\\ [-1;1], \quad &x = 1 \\ 1,  &x > 1 \end{cases} \qquad \partial f_2(x) = \begin{cases} -1,  &x < -1\\ [-1;1], &x = -1 \\ 1,  &x > -1  \end{cases}
$$

So

$$
\partial f(x) = \begin{cases} -2, &x < -1\\ [-2;0], &x = -1 \\ 0,  &-1 < x < 1 \\ [0;2], &x = 1 \\ 2, &x > 1 \\ \end{cases}
$$

## Пример 2

Найти $\partial f(x)$ if $f(x) = \left[ \max(0, f_0(x))\right]^q$. Здесь $f_0(x)$ - выпуклая функция на открытом множестве $S$, и $q \geq 1$.

. . .

Согласно теореме о производной композиции функций (функция $\varphi (x) = x^q$ дифференцируема) и обозначая $g(x) = \max(0, f_0(x))$, имеем:
$$\partial f(x) = q(g(x))^{q-1} \partial g(x)$$

По теореме о субдифференциале поточечного максимума

$$
\partial g(x) = \begin{cases} 
\partial f_0(x), & \quad f_0(x) > 0, \\
\{0\}, & \quad f_0(x) < 0, \\
\{a \mid a = \lambda a', \; 0 \le \lambda \le 1, \; a' \in \partial f_0(x)\}, & \quad f_0(x) = 0 
\end{cases}
$$

## Пример 3. Субдифференциал нормы

Пусть $V$ - конечномерное евклидово пространство, и $x_0 \in V$. Пусть $\lVert \cdot \rVert$ - произвольная норма в пространстве $V$ (не обязательно заданная при помощи скалярного произведения), и пусть $\lVert \cdot \rVert_*$ - соответствующая сопряженная норма. Тогда,

Let $V$ be a finite-dimensional Euclidean space, and $x_0 \in V$. Let $\lVert \cdot \rVert$ be an arbitrary norm in $V$ (not necessarily induced by the scalar product), and let $\lVert \cdot \rVert_*$ be the corresponding conjugate norm. Then,

$$
\partial \lVert \cdot \rVert (x_0) = 
\begin{cases}
B_{\lVert \cdot \rVert_*}(0, 1), & \text{if } x_0 = 0, \\
\{s \in V : \lVert s \rVert_* \leq 1; \langle s, x_0 \rangle = \lVert x_0 \rVert \} = \{s \in V : \lVert s \rVert_* = 1; \langle s, x_0 \rangle = \lVert x_0 \rVert \}, & \text{otherwise.}
\end{cases}
$$

Где $B_{\lVert \cdot \rVert_*}(0,1)$ есть замкнутый единичный относительно сопряженной нормы шар с центром в нуле. Другими словами, вектор $s \in V$ с $\lVert s \rVert_* = 1$ является субградиентом нормы $\lVert \cdot \rVert$ в точке $x_0 \neq 0$ тогда и только тогда, когда неравенство Гёльдера $\langle s, x_0 \rangle \leq \lVert x_0 \rVert$ переходит в равенство.

. . .

:::: {.columns}
::: {.column width="50%"}
Пусть $s \in V$. По определению $s \in \partial \lVert \cdot \rVert (x_0)$ если и только если 

$$
\langle s, x \rangle - \lVert x \rVert \leq \langle s, x_0 \rangle - \lVert x_0 \rVert, \text{ for all } x \in V,
$$

что равносильно

$$
\sup_{x \in V} \{\langle s, x \rangle - \lVert x \rVert\} \leq \langle s, x_0 \rangle - \lVert x_0 \rVert.
$$

По определению супремума, последнее равносильно

$$
\sup_{x \in V} \{\langle s, x \rangle - \lVert x \rVert\} = \langle s, x_0 \rangle - \lVert x_0 \rVert.
$$

:::

. . .

::: {.column width="50%"}

Важно отметить, что выражение слева есть супремум из определения сопряженной функции по Фенхелю для нормы, которая, как известно, записывается так:
$$
\sup_{x \in V} \{\langle s, x \rangle - \lVert x \rVert\} = 
\begin{cases}
0, & \text{if } \lVert s \rVert_* \leq 1, \\
+\infty, & \text{otherwise.}
\end{cases}
$$

Таким образом, выражение равносильно $\lVert s \rVert_* \leq 1$ и $\langle s, x_0 \rangle = \lVert x_0 \rVert$.
:::
::::

## Пример 3. Субдифференциал нормы {.noframenumbered}

Следовательно, остаётся заметить, что для $x_0 \neq 0$ неравенство $\lVert s \rVert_* \leq 1$ должно переходить в равенство, поскольку при $\lVert s \rVert_* < 1$ неравенство Гёльдера влечёт $\langle s, x_0 \rangle \leq \lVert s \rVert_* \lVert x_0 \rVert < \lVert x_0 \rVert$.


Сопряженная норма в примере выше появилась не случайно. Оказывается, что совершенно аналогичным образом для произвольной функции $f$ (не только для нормы) её субдифференциал может быть описан в терминах двойственного объекта - сопряженной по Фенхелю функции. 
