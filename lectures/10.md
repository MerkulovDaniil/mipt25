---
title: "Задача линейного программирования. Симплекс-метод."
author: Даниил Меркулов
institute: Методы оптимизации. МФТИ
format: 
    beamer:
        pdf-engine: pdflatex
        aspectratio: 169
        fontsize: 9pt
        section-titles: true
        incremental: true
        include-in-header: ../files/header.tex  # Custom LaTeX commands and preamble
header-includes:
  - \newcommand{\bgimage}{../files/back10.jpeg}
---


# Примеры задач линейного программирования

## Что такое линейное программирование?

:::: {.columns}

::: {.column width="40%"}
![](LP.pdf)
:::

::: {.column width="60%"}
В общем случае все задачи с линейной целевой функцией и линейными функциональными ограничениями можно считать задачами линейного программирования. Однако существует несколько стандартных формулировок.
$$
\tag{LP.Basic}
\begin{split}
&\min_{x \in \mathbb{R}^n} c^{\top}x \\
\text{s.t. } & Ax \leq b\\
\end{split}
$$
для некоторых векторов $c \in \mathbb{R}^n$, $b \in \mathbb{R}^m$ и матрицы $A \in \mathbb{R}^{m \times n}$, где неравенства — покомпонентные. Мы будем часто использовать эту формулировку для построения интуиции.

. . .

Широко используется **стандартная форма** записи задачи линейного программирования. Пусть заданы векторы $c \in \mathbb{R}^n$, $b \in \mathbb{R}^m$ и матрица $A \in \mathbb{R}^{m \times n}$.
$$
\tag{LP.Standard}
\begin{split}
&\min_{x \in \mathbb{R}^n} c^{\top}x \\
\text{s.t. } & Ax = b\\
& x_i \geq 0, \; i = 1,\dots, n
\end{split}
$$
:::

::::


## Пример: задача о диете

:::: {.columns}

::: {.column width="50%"}
![](diet_LP_ru.pdf)
:::

. . .

::: {.column width="50%"}
Представьте, что вам нужно составить план диеты из некоторых продуктов: бананы, пироги, курица, яйца, рыба. Каждый из продуктов имеет свой вектор питательных веществ. Таким образом, все питательные вещества можно представить в виде матрицы $W$. 

. . .

Предположим, что у нас есть вектор требований для каждого питательного вещества $r \in \mathbb{R}^n$. Нам нужно найти самую дешёвую диету, которая удовлетворяет всем требованиям:

. . .

$$
\begin{split}
&\min_{x \in \mathbb{R}^p} c^{\top}x \\
\text{s.t. } & Wx \succeq r\\
& x_i \geq 0, \; i = 1,\dots, p
\end{split}
$$

[\faPython Open In Colab](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/LP.ipynb#scrollTo=fpT9Ywy5obfu)
:::

::::

## Минимизация выпуклой функции как задача линейного программирования

![Как задача линейного программирования может помочь с общей задачей выпуклой оптимизации](convex_via_LP.pdf){width=75%}

* Функция выпукла, если она может быть представлена как поточечный максимум линейных функций.
* В пространствах большой размерности аппроксимация может потребовать огромного количества функций.
* Существуют более эффективные солверы для выпуклой оптимизации (не сводящиеся к LP).

## Пример: [Транспортная задача](https://jckantor.github.io/ND-Pyomo-Cookbook/notebooks/03.01-Transportation-Networks.html)

Типичная транспортная задача заключается в распределении товара от производителей к потребителям. Цель состоит в минимизации общих затрат на транспортировку при соблюдении ограничений на количество товара на каждом источнике и удовлетворении требований к спросу на каждом пункте назначения.

![Карта Западной Европы. [\faPython Open In Colab](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/LP_transport.ipynb)](LP_west_europe.png)


## Пример: [Транспортная задача](https://jckantor.github.io/ND-Pyomo-Cookbook/notebooks/03.01-Transportation-Networks.html)

:::: {.columns}

::: {.column width="69%"}

| Пункт назначения / Источник | Арнем [\faEuroSign/тонна] |  Гауда [\faEuroSign/тонна] | Спрос [тонн] |
| :------: | :--: | :--: | :-: |
| Лондон | n/a | 2.5 | 125 |
| Берлин | 2.5 | n/a | 175 | 
| Маастрихт | 1.6 | 2.0 | 225 |
| Амстердам | 1.4 | 1.0 | 250 |
| Утрехт | 0.8 | 1.0 | 225 |
| Гаага | 1.4 | 0.8 | 200 |
| **Макс. производство [тонн]** | 550 | 700 | |

\vspace{-0.8cm}

$$
\text{Минимизировать:}\quad \text{Стоимость} = \sum_{c \in \text{Пункты назначения}}\sum_{s \in \text{Источники}} T[c,s] x[c,s]
$$

. . .

$$
\sum_{c \in \text{Пункты назначения}} x[c,s] \leq \text{Поставка}[s] \qquad \forall s \in \text{Источники}
$$

. . .

$$
\sum_{s\in \text{Источники}} x[c,s] = \text{Спрос}[c] \qquad \forall c \in \text{Пункты назначения}
$$

:::

::: {.column width="31%"}
Задачу можно представить в виде следующего графа:

![Граф, связанный с задачей](LP_transport_graph_ru.pdf)
:::

::::


# Как получить задачу линейного программирования?

## Основные преобразования

* Максимум-минимум
    $$
    \begin{split}
    &\min_{x \in \mathbb{R}^n} c^{\top}x \\
    \text{s.t. } & Ax \leq b\\
    \end{split} \quad \leftrightarrow \quad
    \begin{split}
    &\max_{x \in \mathbb{R}^n} -c^{\top}x \\
    \text{s.t. } & Ax \leq b\\
    \end{split} 
    $$

* Равенство к неравенству
    $$
    Ax = b \leftrightarrow 
    \begin{cases}
    Ax \leq  b\\
    Ax \geq b
    \end{cases}
    $$

* Неравенство к равенству, увеличивая размерность задачи на $m$.
    $$
    Ax \leq b \leftrightarrow 
    \begin{cases}
    Ax + z =  b\\
    z \geq 0
    \end{cases}
    $$

* Неотрицательные переменные
    $$
    x \leftrightarrow 
    \begin{cases}
    x = x_+ - x_-\\
    x_+ \geq 0 \\
    x_- \geq 0
    \end{cases}
    $$

## Пример: задача аппроксимации Чебышева

$$
\min_{x \in \mathbb{R}^n} \|Ax - b\|_\infty \leftrightarrow \min_{x \in \mathbb{R}^n} \max_{i} |a_i^T x - b_i|
$$

Можно записать эквивалентную задачу линейного программирования с заменой максимальной координаты вектора:

. . .

$$
\begin{split}
&\min_{t \in \mathbb{R}, x \in \mathbb{R}^n} t \\
\text{s.t. } & a_i^T x - b_i \leq t, \; i = 1,\dots, m\\
& -a_i^T x + b_i \leq t, \; i = 1,\dots, m
\end{split}
$$

## Пример: задача $\ell_1$ аппроксимации

$$
\min_{x \in \mathbb{R}^n} \|Ax - b\|_1 \leftrightarrow \min_{x \in \mathbb{R}^n} \sum_{i=1}^m |a_i^T x - b_i|
$$

Можно записать эквивалентную задачу линейного программирования с заменой суммы координат вектора:

. . .

$$
\begin{split}
&\min_{t \in \mathbb{R}^m, x \in \mathbb{R}^n} \mathbf{1}^T t \\
\text{s.t. } & a_i^T x - b_i \leq t_i, \; i = 1,\dots, m\\
& -a_i^T x + b_i \leq t_i, \; i = 1,\dots, m
\end{split}
$$

## Задача смешивания: от нелинейных ограничений к ЛП ^[[\beamerbutton{Source}](https://jckantor.github.io/ND-Pyomo-Cookbook/notebooks/02.03-Linear-Blending-Problem.html)]


:::: {.columns}

::: {.column width="60%"}
Производственное предприятие получает заказ на 100 литров раствора с определённой концентрацией (например, 4% сахарного раствора). На складе есть:

| Компонент | Сахар (%) | Стоимость (\$/л) |
|--|:-:|:-:|
| **Концентрат A (Добрый кола)** | 10.6 | 1.25 |
| **Концентрат B (Север кола)** | 4.5 | 1.02 |
| **Вода (Псыж)** | 0.0 | 0.62|
**Цель**: Найти смесь с минимальной стоимостью, которая удовлетворит заказ.


### Целевая функция

. . .

Минимизировать стоимость:
$$
\text{Cost} = \sum_{c \in C} x_c P_c
$$
где $x_c$ — объём используемого компонента $c$, и $P_c$ — его цена.

:::

. . .

::: {.column width="50%"}
### Ограничение на объём

. . .

Убедитесь, что общий объём $V$:
$$
V = \sum_{c \in C} x_c
$$

#### Ограничение на состав

. . .

Убедитесь, что содержание сахара — 4%:
$$
\bar{A} = \frac{\sum_{c \in C} x_c A_c}{\sum_{c \in C} x_c}
$$

. . .

Линеаризованная версия:
$$
0 = \sum_{c \in C} x_c (A_c - \bar{A})
$$
Это можно решить с помощью линейного программирования. 

[\faPython Код](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/LP_blending.ipynb)

:::

::::

# Симплекс-метод

## Геометрия симплекс-метода

:::: {.columns}

::: {.column width="50%"}
![](LP_basis_ru.pdf)
:::

::: {.column width="50%"}
Рассмотрим следующую простую формулировку задачи линейного программирования:
<!-- , которая, фактически, является двойственной к стандартной форме: -->

$$
\tag{LP.Inequality}
\begin{split}
&\min_{x \in \mathbb{R}^n} c^{\top}x \\
\text{s.t. } & Ax \leq b
\end{split}
$$

* Определение: **базис** $\mathcal{B}$ — это подмножество $n$ (целых) чисел между $1$ и $m$, такое что $\text{rank} A_{\mathcal{B}} = n$. 
* Обратите внимание, что мы можем связать подматрицу $A_{\mathcal{B}}$ и соответствующую правую часть $b_{\mathcal{B}}$ с базисом $\mathcal{B}$. 
* Также мы можем получить точку пересечения всех этих гиперплоскостей из базиса: $x_{\mathcal{B}} = A^{-1}_{\mathcal{B}} b_{\mathcal{B}}$. 
* Если $A x_{\mathcal{B}} \leq b$, то базис $\mathcal{B}$ является **допустимым**. 
* Базис $\mathcal{B}$ оптимален, если $x_{\mathcal{B}}$ является решением задачи $\text{LP.Inequality}$.
* $x_{\mathcal{B}}$ называют **базисной точкой** или базисным решением (иногда её тоже называют **базисом**).
:::

::::

## Если решение задачи линейного программирования существует, то оно лежит в вершине

:::: {.columns}

::: {.column width="35%"}
![](LP.pdf)
:::

::: {.column width="65%"}

:::{.callout-theorem}
1. Если задача линейного программирования в стандартной форме имеет непустое бюджетное множество, то существует по крайней мере одна допустимая базисная точка.
1. Если задача линейного программирования в стандартной форме имеет решения, то по крайней мере одно из таких решений является оптимальной базисной точкой.
1. Если задача линейного программирования в стандартной форме допустима и ограничена, то она имеет оптимальное решение.

. . .

Для доказательства см. теорему 13.2 в [Numerical Optimization by Jorge Nocedal and Stephen J. Wright](https://fmin.xyz/assets/files/NumericalOptimization.pdf)
:::

:::
::::

Верхнеуровневая идея симплекс-метода: 

:::: {.columns}

::: {.column width="50%"}
* Убедитесь, что вы находитесь в вершине. 
* Проверьте оптимальность.
:::
::: {.column width="50%"}
* Если необходимо, перейдите к другой вершине (измените базис).
* Повторяйте, пока не сойдётесь.
:::
::::


## Оптимальный базис

:::: {.columns}

::: {.column width="40%"}
![](LP_basis_ru.pdf)
:::

. . .

::: {.column width="60%"}
Поскольку у нас есть базис, мы можем разложить наш целевой вектор $c$ в этом базисе и найти скалярные коэффициенты $\lambda_{\mathcal{B}}$:
$$
\lambda^T_{\mathcal{B}} A_{\mathcal{B}} = c^T \leftrightarrow \lambda^T_{\mathcal{B}} = c^T A_{\mathcal{B}}^{-1}
$$

. . .

:::{.callout-theorem}
Если все компоненты $\lambda_{\mathcal{B}}$ неположительны и $\mathcal{B}$ допустим, то $\mathcal{B}$ оптимален.
:::

. . .

**Доказательство**
Предположим противное, то есть $\lambda_{\mathcal{B}} \leq 0$ и $\mathcal{B}$ допустим, но не оптимален.
$$
\begin{split}
\uncover<+->{\exists x^*: Ax^* &\leq b, c^T x^* < c^T x_{\mathcal{B}} \\}
\uncover<+->{A_{\mathcal{B}} x^* &\leq b_{\mathcal{B}}}  \uncover<+->{ \mid \lambda_{\mathcal{B}}^T \cdot  \leq 0 \\}
\uncover<+->{\lambda_{\mathcal{B}}^T A_{\mathcal{B}} x^* &\geq \lambda_{\mathcal{B}}^T b_{\mathcal{B}} \\}
\uncover<+->{c^T x^* & \geq \lambda_{\mathcal{B}}^T A_{\mathcal{B}} x_{\mathcal{B}} \\}
\uncover<+->{c^T x^* & \geq c^T  x_{\mathcal{B}} \\}
\end{split}
$$
:::
::::

## Изменение базиса

:::: {.columns}

::: {.column width="35%"}
![](LP_change_ru.pdf)
Предположим, что некоторые из коэффициентов $\lambda_{\mathcal{B}}$ положительны. В этом случае необходимо осуществить переход по ребру многогранника к новой вершине, то есть произвести замену базиса.
:::

. . .

::: {.column width="65%"}
* Предположим, что у нас есть базис $\mathcal{B}$: $\lambda^T_{\mathcal{B}} = c^T A_{\mathcal{B}}^{-1}$
* Предположим, что $\lambda^k_{\mathcal{B}} > 0$. Мы хотим удалить $k$ из базиса и сформировать новый:
    $$
    \uncover<+->{ \begin{cases}
    A_{\mathcal{B} \textbackslash \{k\}} d = 0 \\
    a^T_k d = -1
    \end{cases}} \qquad \uncover<+->{ c^Td } \uncover<+->{ = \lambda^T_{\mathcal{B}} A_{\mathcal{B}} d } \uncover<+->{ = \sum\limits_{i=1}^n \lambda^i_{\mathcal{B}}  (A_{\mathcal{B}} d)^i  } \uncover<+->{ = -\lambda^k_{\mathcal{B}} < 0 }
    $$

* Для всех $j \notin \mathcal{B}$ рассчитаем размер шага проекции:
    $$
    \mu_j = \frac{b_j - a_j^T x_{\mathcal{B}}}{a_j^T d}
    $$
* Определим новую вершину, которую мы добавим в новый базис:
    $$
    \begin{split}
    t = \text{arg}\min_j \{\mu_j \mid \mu_j > 0\} \\
    \mathcal{B}' = \mathcal{B}\textbackslash \{k\} \cup \{t\} \\ 
    x_{\mathcal{B'}} = x_{\mathcal{B}} + \mu_t d = A^{-1}_{\mathcal{B'}} b_{\mathcal{B'}}
    \end{split}
    $$
* Обратите внимание, что изменение базиса приводит к уменьшению целевой функции: $c^Tx_{\mathcal{B'}} = c^T(x_{\mathcal{B}} + \mu_t d) = c^Tx_{\mathcal{B}} + \mu_t c^Td$

:::
::::

## Поиск начального допустимого базиса

:::: {.columns}

::: {.column width="50%"}
Нам нужно решить следующую задачу:
$$
\begin{split}
&\min_{x \in \mathbb{R}^n} c^{\top}x \\
\text{s.t. } & Ax \leq b
\end{split}
$$ {#eq-LP_ineq}
Предложенный алгоритм требует начального допустимого базиса.
:::

. . .

::: {.column width="50%"}
Начнём с переформулировки задачи:
$$
\begin{split}
&\min_{y \in \mathbb{R}^n, z \in \mathbb{R}^n} c^{\top}(y-z) \\
\text{s.t. } & Ay - Az \leq b \\ 
& y \geq 0, z \geq 0 \\ 
\end{split}
$$ {#eq-LP_ineq_new}
:::
::::

. . .

Зная решение задачи (-@eq-LP_ineq_new), можно восстановить решение задачи (-@eq-LP_ineq), и наоборот.

$$
x = y-z \qquad \Leftrightarrow \qquad y_i = \max(x_i, 0), \quad z_i = \max(-x_i, 0)
$$

Теперь мы попытаемся сформулировать новую задачу линейного программирования, решение которой будет допустимой базисной точкой для [Задачи @eq-LP_ineq_new]. Это означает, что мы сначала запускаем симплекс-метод для задачи Phase-1, а затем запускаем задачу Phase-2 с известным начальным решением. Обратите внимание, что допустимое базисное решение для Phase-1 должно быть легко вычислимо.


## Поиск начального допустимого базиса


:::: {.columns}

::: {.column width="50%"}
$$
\tag{Фаза-2 (главная задача ЛП)}
\begin{split}
&\min_{y \in \mathbb{R}^n, z \in \mathbb{R}^n} c^{\top}(y-z) \\
\text{s.t. } & Ay - Az \leq b \\ 
& y \geq 0, z \geq 0 \\ 
\end{split}
$$

. . .

$$
\tag{Фаза-1}
\begin{split}
&\min_{\xi \in \mathbb{R}^m, y \in \mathbb{R}^n, z \in \mathbb{R}^n} \sum\limits_{i=1}^m \xi_i \\
\text{s.t. } & Ay - Az \leq b + \xi \\ 
& y \geq 0, z \geq 0, \xi \geq 0 \\ 
\end{split}
$$
:::

. . .

::: {.column width="50%"}
* Если Фаза-2 (главная задача ЛП) имеет допустимое решение, то оптимум Фаза-1 равен нулю (т.е. все переменные $\xi_i$ равны нулю).
    
    **Доказательство:** тривиальная проверка.
* Если оптимум Фаза-1 равен нулю (т.е. все переменные $\xi_i$ равны нулю), то мы получаем допустимый базис для Фаза-2.
    
    **Доказательство:** тривиальная проверка.

:::
::::

. . .

* Теперь мы знаем, что если мы можем решить задачу Фаза-1, то мы либо найдём начальную точку для симплекс-метода в исходном методе (если переменные $\xi_i$ равны нулю), либо проверим, что исходная задача не имеет допустимого решения (если переменные $\xi_i$ не равны нулю).
* Но как решить задачу Фаза-1? Она имеет допустимое базисное решение (задача имеет $2n + m$ переменных, и точка ниже гарантирует, что $2n + m$ неравенств удовлетворяются как равенства (активны).)

. . .

    $$
    z = 0 \quad y = 0 \quad \xi_i = \max(0, -b_i)
    $$

# Сходимость симплекс-метода

## Неограниченное бюджетное множество

:::: {.columns}

::: {.column width="50%"}
![](LP_unbounded_ru.pdf)
:::

::: {.column width="50%"}
В этом случае не найдётся ни одного положительного $\mu_j$.
:::
::::

## Вырожденность вершин

:::: {.columns}

::: {.column width="50%"}
![](LP_degenerate_ru.pdf)
:::

::: {.column width="50%"}
Случаи вырожденности требуют особого рассмотрения. В отсутствие вырожденности на каждой итерации гарантируется монотонное убывание значения целевой функции.
:::
::::

## Экспоненциальная сходимость

:::: {.columns}

::: {.column width="50%"}
![](LP_IPM.pdf)
:::

::: {.column width="50%"}

* Много прикладных задач может быть сформулировано в виде задач линейного программирования.
* Симплекс-метод прост в своей основе, но в худшем случае может работать экспоненциально долго.
* Метод эллипсоидов Хачияна (1979) стал первым алгоритмом с доказанной полиномиальной сложностью для задач ЛП. Однако он обычно работает медленнее, чем симплекс-метод в реальных небольших задачах.
* Основной прорыв — метод Кармаркара (1984) для решения задач ЛП с использованием метода внутренней точки.
* Методы внутренней точки являются последним словом в этой области. Тем не менее, для типовых задач ЛП качественные реализации симплекс-метода и методов внутренней точки показывают схожую производительность.
:::
::::

## Пример [Klee Minty](https://en.wikipedia.org/wiki/Klee%E2%80%93Minty_cube)

Так как число вершин конечно, сходимость алгоритма гарантирована (за исключением вырожденных случаев, которые здесь не рассматриваются). Тем не менее, сходимость может быть экспоненциально медленной из-за потенциально большого числа вершин. Существует пример, в котором симплекс-метод вынужден пройти через все вершины многогранника.

:::: {.columns}

::: {.column width="60%"}
В следующей задаче симплекс-метод должен проверить $2^n - 1$ вершин с $x_0 = 0$.


$$
\begin{split} 
& \max_{x \in \mathbb{R}^n} 2^{n-1}x_1 + 2^{n-2}x_2 + \dots + 2x_{n-1} + x_n \\
\text{s.t. } & x_1 \leq 5 \\
& 4x_1 + x_2 \leq 25 \\
& 8x_1 + 4x_2 + x_3 \leq 125 \\
& \ldots \\
& 2^n x_1 + 2^{n-1}x_2 + 2^{n-2}x_3 + \ldots + x_n \leq 5^n\\ 
& x \geq 0  
\end{split}
$$
:::

::: {.column width="40%"}
![](LP_KM.pdf)
:::
::::


# Смешанное целочисленное программирование (MIP)

## Сложность MIP

:::: {.columns}

::: {.column width="50%"}
Рассмотрим следующую задачу смешанного целочисленного программирования (MIP):
$$
\begin{split}
z = 8x_1 + 11x_2 + 6x_3 + 4x_4 &\to \max_{x_1, x_2, x_3, x_4} \\
\text{s.t. }  5x_1+7x_2+4x_3+3x_4 &\leq 14 \\
x_i \in \{0,1\} \quad \forall i &
\end{split}
$$ {#eq-mip}
:::

. . .

::: {.column width="50%"}
Упростим её до:
$$
\begin{split}
z = 8x_1 + 11x_2 + 6x_3 + 4x_4 &\to \max_{x_1, x_2, x_3, x_4} \\
\text{s.t. }  5x_1+7x_2+4x_3+3x_4 &\leq 14 \\
x_i \in [0,1] \quad \forall i &
\end{split}
$${#eq-mip_lp_relax}
:::
::::

. . .

:::: {.columns}

::: {.column width="50%"}
Оптимальное решение
$$
x_1=0, x_2=x_3=x_4=1, \text{ и } z=21.
$$
:::

. . .

::: {.column width="50%"}
Оптимальное решение
$$
x_1 = x_2 = 1, x_3 = 0.5, x_4 = 0, \text{ и } z = 22.
$$

. . .

* Округление $x_3 = 0$: даёт $z = 19$.
* Округление $x_3 = 1$: недопустимо.
:::
::::

. . .

:::{.callout-important}

### MIP намного сложнее, чем ЛП

* Наивное округление решения, полученного для ЛП-релаксации исходной задачи MIP, может привести к недопустимому или неоптимальному решению.
* Общая задача MIP является NP-трудной задачей.
* Однако, если матрица коэффициентов MIP является [*полностью унимодулярной матрицей*](https://en.wikipedia.org/wiki/Integer_programming), то она может быть решена за полиномиальное время.
:::

## Непредсказуемая сложность MIP

:::: {.columns}

::: {.column width="35%"}
* Трудно предсказать, что будет решено быстро, а что потребует много времени
* [\faLink Датасет](https://miplib.zib.de/index.html)
* [\faPython Код](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/miplib.ipynb)
:::
::: {.column width="65%"}
![](miplib.pdf)
:::
::::

## Прогресс аппаратного vs программного обеспечения

Что бы вы выбрали, если предположить, что вопрос поставлен корректно (вы можете скомпилировать ПО для любого оборудования, и задача в обоих случаях одна и та же)? Мы рассмотрим период с 1992 по 2023 год.

:::: {.columns}

::: {.column width="50%"}
:::{.callout-caution}

### Аппаратное обеспечение

Решение MIP с использованием старого ПО на современном оборудовании

:::
:::
::: {.column width="50%"}
:::{.callout-caution}

### Программное обеспечение

Решение MIP с использованием современного ПО на старом оборудовании
:::
:::
::::

. . .

:::: {.columns}

::: {.column width="50%"}
$$
\approx 1.664.510\text{ x ускорение}
$$
Закон Мура утверждает, что вычислительная мощность удваивается каждые 18 месяцев.

:::
::: {.column width="50%"}
$$
\approx 2.349.000\text{ x ускорение}
$$
Р. Бикси провёл масштабный эксперимент по сравнению производительности всех версий CPLEX с 1992 по 2007 год и измерил общий прогресс ПО ($29 000$ раз), позже (в 2009 году) он стал одним из основателей Gurobi Optimization, которое дало дополнительное $\approx 81$ [ускорение](https://www.gurobi.com/features/gurobi-optimizer-delivers-unmatched-performance/) на MIP.
:::
::::

. . .

Оказывается, что если вам нужно решить MIP, лучше использовать старый компьютер и современные методы, чем наоборот, самый новый компьютер и методы начала 1990-х годов!^[[\beamerbutton{R. Bixby report}](https://www.math.uni-bielefeld.de/documenta/vol-ismp/25_bixby-robert.pdf) [\beamerbutton{Recent study}](https://plato.asu.edu/talks/japan23.pdf)]

## Источники

* [Теория оптимизации (MATH4230) курс @ CUHK, профессор Тейюн Цень](https://www.math.cuhk.edu.hk/course_builder/1920/math4230/Lagrangeduality-example.pdf)
