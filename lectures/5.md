---
title: "Субградиент и субдифференциал"
author: Даниил Меркулов
institute: Методы оптимизации. МФТИ
format: 
    beamer:
        pdf-engine: xelatex
        aspectratio: 169
        fontsize: 9pt
        section-titles: true
        incremental: true
        include-in-header: ../files/xeheader.tex  # Custom LaTeX commands and preamble
header-includes:
 - \newcommand{\bgimage}{../files/back7.jpeg}
---

# Негладкие задачи

## Задача наименьших квадратов с $\ell_1$- регуляризацией

[![](l1_regularization.jpeg)](https://fmin.xyz/assets/Notebooks/Regularization_horizontal.mp4)

## Нормы не являются гладкими

$$
\min_{x \in \mathbb{R}^n} f(x),
$$

Рассмотрим классическую выпуклую задачу оптимизации. Мы предполагаем, что $f(x)$ является выпуклой функцией, но теперь мы не требуем гладкости. 

![Нормы конусов для разных $p$ — нормы не являются гладкими](norm_cones.pdf){width=90%}

## Пример Вульфа

![Пример Вульфа. [\faPython Открыть в Colab](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/subgrad.ipynb)](wolfe_3d.pdf){width=90%}


# Вычисление субградиента

## Линейная нижняя оценка выпуклых функций

:::: {.columns}

::: {.column width="60%"}
![Линейная аппроксимация Тейлора служит глобальной нижней оценкой для выпуклой функции](Subgrad.pdf)
:::

::: {.column width="40%"}
Важное свойство непрерывной выпуклой функции $f(x)$ заключается в том, что для любой выбранной точки $x_0$ для всех $x \in \text{dom } f$ выполняется неравенство:
$$
f(x) \geq f(x_0) + \langle g, x - x_0 \rangle
$$

. . .

для некоторого вектора $g$, т.е. касательная к графику функции является *глобальной* нижней оценкой для функции. 

* Если $f(x)$ дифференцируема, то $g = \nabla f(x_0)$.
* Не все непрерывные выпуклые функции дифференцируемы.

. . .

Мы не хотим потерять такое удобное свойство.
:::

::::

## Субградиент и субдифференциал

Вектор $g$ называется **субградиентом** функции $f(x): S \to \mathbb{R}$ в точке $x_0$, если $\forall x \in S$:
$$
f(x) \geq f(x_0) + \langle g, x - x_0 \rangle
$$

. . .

Множество всех субградиентов функции $f(x)$ в точке $x_0$ называется **субдифференциалом** функции $f$ в точке $x_0$ и обозначается $\partial f(x_0)$.

. . .

![Субдифференциал — это множество всех возможных субградиентов](Subdifferential.pdf)

## Субградиент и субдифференциал

Найдите $\partial f(x)$, если $f(x) = |x|$

. . .

![Субдифференциал $\vert x \vert$](subgradmod.pdf){width=85%}

## Свойства субдифференциала

:::: {.columns}
::: {.column width="50%"}
* Если $x_0 \in \mathbf{ri }(S)$, то $\partial f(x_0)$ является выпуклым компактным множеством.
* Выпуклая функция $f(x)$ дифференцируема в точке $x_0\Rightarrow \partial f(x_0) = \{\nabla f(x_0)\}$.
* Если $\partial f(x_0) \neq \emptyset \quad \forall x_0 \in S$, то $f(x)$ выпукла на $S$.

. . .


::: {.callout-theorem}

### Субдифференциал дифференцируемой функции

Пусть $f : S \to \mathbb{R}$ — функция, определенная на множестве $S$ в евклидовом пространстве $\mathbb{R}^n$. Если $x_0 \in \mathbf{ri }(S)$ и $f$ дифференцируема в точке $x_0$, то либо $\partial f(x_0) = \emptyset$ либо $\partial f(x_0) = \{\nabla f(x_0)\}$. Более того, если функция $f$ выпукла, то первая ситуация невозможна.
:::
:::

. . .

::: {.column width="50%"}

**Доказательство**

1. Пусть $s \in \partial f(x_0)$ для некоторого $s \in \mathbb{R}^n$ отличного от $\nabla f(x_0)$. Пусть $v \in  \mathbb{R}^n$ — единичный вектор. Поскольку $x_0$ является внутренней точкой множества $S$, существует $\delta > 0$ такое, что $x_0 + tv \in S$ для всех $0 < t < \delta$. По определению субградиента:
 $$
    f(x_0 + tv) \geq f(x_0) + t \langle s, v \rangle
 $$

. . .

что влечёт:
$$
\frac{f(x_0 + tv) - f(x_0)}{t} \geq \langle s, v \rangle
$$
для всех $0 < t < \delta$. Переходя к пределу при $t \to 0$ и используя определение градиента, получаем:
$$
\langle \nabla f(x_0), v \rangle = \lim_{{t \to 0; 0 < t < \delta}} \frac{f(x_0 + tv) - f(x_0)}{t} \geq \langle s, v \rangle
$$
:::
::::

## Свойства субдифференциала

2. Отсюда $\langle s - \nabla f(x_0), v \rangle \geq 0$. В силу произвольности $v$ можно выбрать 
 $$
    v = -\frac{s - \nabla f(x_0)}{\| s - \nabla f(x_0) \|},
    $$ 
 которое приводит к $s = \nabla f(x_0)$.
3. Более того, если функция $f$ выпукла, то согласно дифференциальному условию выпуклости $f(x) \geq f(x_0) + \langle \nabla f(x_0), x - x_0 \rangle$ для всех $x \in S$. Но по определению это означает, что $\nabla f(x_0) \in \partial f(x_0)$.

## Субдифференцируемость и выпуклость

:::{.callout-question}
Верно ли, что если функция имеет субдифференциал в некоторой точке, то функция выпукла?
:::

. . .


Найдите $\partial f(x)$, если $f(x) = \sin x, x \in [\pi/2; 2\pi]$
![](sin.pdf)

$$
\partial_S f(x) = 
\begin{cases} 
(-\infty ; \cos x_0], &x = \frac\pi2 \\ 
\emptyset, &x \in \left(\frac\pi2; x_0\right) \\
\cos x, &x \in [x_0; 2\pi) \\
[1; \infty), &x = 2\pi
\end{cases}
$$

## Субдифференцируемость и выпуклость

:::{.callout-question}
Верно ли, что если функция выпукла, то она имеет субградиент в любой точке?
:::

. . .

Выпуклость следует из субдифференцируемости в любой точке. Естественный вопрос заключается в том, верно ли обратное: является ли всякая выпуклая функция субдифференцируемой? Оказывается, в общем случае ответ на этот вопрос отрицателен.

Пусть $f : [0,\infty) \to \mathbb{R}$ определена как $f(x) := -\sqrt{x}$. Тогда, $\partial f(0) = \emptyset$.

Предположим, что $s \in \partial f(0)$ для некоторого $s \in \mathbb{R}$. Тогда, по определению, мы должны иметь $sx \leq -\sqrt{x}$ для всех $x \geq 0$. Из этого мы можем вывести $s \leq -\sqrt{1}$ для всех $x > 0$. Переходя к пределу при $x$ стремящемся к 0 справа, мы получаем $s \leq -\infty$, что невозможно.


## Вычисление субдифференциалов

:::: {.columns}
::: {.column width="50%"}
:::{.callout-theorem}
### Теорема Моро — Роккафеллара (субдифференциал линейной комбинации)
Пусть $f_i(x)$ — выпуклые функции на выпуклых множествах $S_i, \; i = \overline{1,n}$. Тогда если $\bigcap\limits_{i=1}^n \mathbf{ri } (S_i) \neq \emptyset$, то функция $f(x) = \sum\limits_{i=1}^n a_i f_i(x), \; a_i > 0$ имеет субдифференциал $\partial_S f(x)$ на множестве $S = \bigcap\limits_{i=1}^n S_i$ и 
$$
\partial_S f(x) = \sum\limits_{i=1}^n a_i \partial_{S_i} f_i(x).
$$
:::
:::

. . .

::: {.column width="50%"}
::: {.callout-theorem}

### Теорема Дубовицкого — Милютина (субдифференциал поточечного максимума) 

Пусть $f_i(x)$ — выпуклые функции на открытом выпуклом множестве $S \subseteq \mathbb{R}^n, \; x_0 \in S$, и поточечный максимум определяется как $f(x) = \underset{i}{\operatorname{max}} f_i(x)$. Тогда:
$$
\partial_S f(x_0) = \mathbf{conv}\left\{  \bigcup\limits_{i \in I(x_0)} \partial_S f_i(x_0) \right\},
$$
$$
\quad I(x) = \{ i \in [1:m]: f_i(x) = f(x)\}
$$
:::
:::
::::

## Вычисление субдифференциала

* $\partial (\alpha f)(x) = \alpha \partial f(x)$, для $\alpha \geq 0$
* $\partial (\sum f_i)(x) = \sum \partial f_i (x)$, $f_i$ — выпуклые функции
* $\partial (f(Ax + b))(x) = A^T\partial f(Ax + b)$, $f$ — выпуклая функция
* $z \in \partial f(x)$ тогда и только тогда, когда $x \in \partial f^*(z)$.

## Связь с выпуклой геометрией

:::: {.columns}
::: {.column width="60%"}

Для выпуклого множества $S \subseteq \mathbb{R}^n$, рассмотрим индикаторную функцию $I_S : \mathbb{R}^n \to \mathbb{R}$,

$$
I_S(x) = I\{ x \in S \} = \begin{cases} 
0 & \text{if } x \in S \\
\infty & \text{if } x \notin S 
\end{cases}
$$
\pause
Для $x \in S$, $\partial I_S(x) = \mathcal{N}_S(x)$, **нормальный конус** для $S$ в $x$:
$$
\mathcal{N}_S(x) = \{ g \in \mathbb{R}^n : g^T x \geq g^T y \text{ for any } y \in S \}
$$
\pause
**Почему?** По определнию субградиента $g$,
$$
I_S(y) \geq I_S(x) + g^T (y - x) \quad \text{for all } y
$$

- При $y \notin S$, $I_S(y) = \infty$
- При $y \in S$, this means $0 \geq g^T (y - x)$

:::

::: {.column width="40%"}
![](normal_cone.jpg)
:::
::::

## Условия Оптимальности

Для любой $f$ (выпуклой или нет),
$$
f(x^\star) = \min_x f(x) \quad \Longleftrightarrow \quad 0 \in \partial f(x^\star)
$$

То есть, $x^\star$ является точкой минимума тогда и только тогда, когда 0 является субградиентом функции $f$ в точке $x^\star$. Это утверждение называется **субградиентное условие оптимальности**

Почему? Легко: если $g = 0$ является субградиентом, это значит что для всех $y$ 
$$
f(y) \geq f(x^\star) + 0^T (y - x^\star) = f(x^\star)
$$

Отметим, что для выпуклой и дифференцируемой функций $f$ верно
$$
\partial f(x) = \{\nabla f(x)\}
$$

## Получение условия оптимальности первого порядка

:::: {.columns}
::: {.column width="50%"}

Попробуем записать общее **условие оптимальности первого порядка**. Вспомним, что решением задачи

$$
\min_x f(x) \text{ subject to } x \in S
$$

является точка $x$, для выпуклой и дифференцируемой $f$, в том и только в том случае, если

$$
\nabla f(x)^T (y - x) \geq 0 \quad \text{for all } y \in S
$$

Интуитивно: написанное выше означает, что функция увеличивается по мере движения от точки $x$. Как это доказать? Во-первых, перепишем задачу в следующем виде:

$$
\min_x f(x) + I_S(x)
$$

Теперь воспользуемся условием оптимальности в субградиентной форме:

$$
0 \in \partial (f(x) + I_S(x))
$$

:::
::: {.column width="50%"}
![](general_first_order_local_optimality.pdf)
:::
::::


## Получение условия оптимальности первого порядка {.noframenumbering}

:::: {.columns}
::: {.column width="50%"}

Заметим, что
$$
0 \in \partial (f(x) + I_S(x))
$$
\pause
$$
\Leftrightarrow 0 \in \{\nabla f(x)\} + \mathcal{N}_S(x)
$$
\pause
$$
\Leftrightarrow -\nabla f(x) \in \mathcal{N}_S(x)
$$
\pause
$$
\Leftrightarrow -\nabla f(x)^T x \geq -\nabla f(x)^T y \text{ for all } y \in S
$$
\pause
$$
\Leftrightarrow \nabla f(x)^T (y - x) \geq 0 \text{ for all } y \in S
$$
что и требовалось.

Замечание: условие $0 \in \partial f(x) + \mathcal{N}_S(x)$ является **общим условием** оптимальности для выпуклых задач. Однако с ним не всегда удобно работать (ККТ удобнее, про них позже). 

:::
::: {.column width="50%"}
![](general_first_order_local_optimality.pdf)
:::
::::

## Пример 1 {.t}

::: {.callout-example}
Найти $\partial f(x)$, if $f(x) = |x - 1| + |x + 1|$
:::

. . .

$$
\partial f_1(x) = \begin{cases} -1,  &x < 1\\ [-1;1], \quad &x = 1 \\ 1,  &x > 1 \end{cases} \qquad \partial f_2(x) = \begin{cases} -1,  &x < -1\\ [-1;1], &x = -1 \\ 1,  &x > -1  \end{cases}
$$
\pause
Итак,
$$
\partial f(x) = \begin{cases} -2, &x < -1\\ [-2;0], &x = -1 \\ 0,  &-1 < x < 1 \\ [0;2], &x = 1 \\ 2, &x > 1 \\ \end{cases}
$$

## Пример 2 {.t}

Найти $\partial f(x)$ if $f(x) = \left[ \max(0, f_0(x))\right]^q$. Здесь $f_0(x)$ - выпуклая функция на открытом множестве $S$, и $q \geq 1$.

\pause

Согласно теореме о производной композиции функций (функция $\varphi (x) = x^q$ дифференцируема) и обозначая $g(x) = \max(0, f_0(x))$, имеем:
$$\partial f(x) = q(g(x))^{q-1} \partial g(x)$$

\pause

По теореме о субдифференциале поточечного максимума

$$
\partial g(x) = \begin{cases} 
\partial f_0(x), & \quad f_0(x) > 0, \\
\{0\}, & \quad f_0(x) < 0, \\
\{a \mid a = \lambda a', \; 0 \le \lambda \le 1, \; a' \in \partial f_0(x)\}, & \quad f_0(x) = 0 
\end{cases}
$$

## Пример 3. Субдифференциал нормы {.t}

Пусть $V$ - конечномерное евклидово пространство, и $x_0 \in V$. Пусть $\lVert \cdot \rVert$ - произвольная норма в пространстве $V$, и пусть $\lVert \cdot \rVert_*$ - соответствующая сопряженная норма. Тогда,
$$
\partial \lVert \cdot \rVert (x_0) = 
\begin{cases}
B_{\lVert \cdot \rVert_*}(0, 1), & \text{ если } x_0 = 0, \\
\{s \in V : \lVert s \rVert_* \leq 1; \langle s, x_0 \rangle = \lVert x_0 \rVert \} = \{s \in V : \lVert s \rVert_* = 1; \langle s, x_0 \rangle = \lVert x_0 \rVert \}, & \text{иначе.}
\end{cases}
$$

Где $B_{\lVert \cdot \rVert_*}(0,1)$ есть замкнутый единичный относительно сопряженной нормы шар с центром в нуле. Другими словами, вектор $s \in V$ с $\lVert s \rVert_* = 1$ является субградиентом нормы $\lVert \cdot \rVert$ в точке $x_0 \neq 0$ тогда и только тогда, когда неравенство Гёльдера $\langle s, x_0 \rangle \leq \lVert x_0 \rVert$ переходит в равенство.
\pause

:::: {.columns}
::: {.column width="50%"}
Пусть $s \in V$. По определению $s \in \partial \lVert \cdot \rVert (x_0)$ если и только если 
$$
\langle s, x \rangle - \lVert x \rVert \leq \langle s, x_0 \rangle - \lVert x_0 \rVert, \text{ for all } x \in V,
$$
что равносильно
$$
\sup_{x \in V} \{\langle s, x \rangle - \lVert x \rVert\} \leq \langle s, x_0 \rangle - \lVert x_0 \rVert.
$$
По определению супремума, последнее равносильно
$$
\sup_{x \in V} \{\langle s, x \rangle - \lVert x \rVert\} = \langle s, x_0 \rangle - \lVert x_0 \rVert.
$$

:::

. . .

::: {.column width="50%"}

Важно отметить, что выражение слева есть супремум из определения сопряженной функции по Фенхелю для нормы, которая, как известно, записывается так:
$$
\sup_{x \in V} \{\langle s, x \rangle - \lVert x \rVert\} = 
\begin{cases}
0, & \text{if } \lVert s \rVert_* \leq 1, \\
+\infty, & \text{otherwise.}
\end{cases}
$$

Таким образом, выражение равносильно $\lVert s \rVert_* \leq 1$ и $\langle s, x_0 \rangle = \lVert x_0 \rVert$.
:::
::::

## Пример 3. Субдифференциал нормы {.noframenumbered}

Следовательно, остаётся заметить, что для $x_0 \neq 0$ неравенство $\lVert s \rVert_* \leq 1$ должно переходить в равенство, поскольку при $\lVert s \rVert_* < 1$ неравенство Гёльдера влечёт $\langle s, x_0 \rangle \leq \lVert s \rVert_* \lVert x_0 \rVert < \lVert x_0 \rVert$.


Сопряженная норма в примере выше появилась не случайно. Оказывается, что совершенно аналогичным образом для произвольной функции $f$ (не только для нормы) её субдифференциал может быть описан в терминах двойственного объекта - сопряженной по Фенхелю функции. 
